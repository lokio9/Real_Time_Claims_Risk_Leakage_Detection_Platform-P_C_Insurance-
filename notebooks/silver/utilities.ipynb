{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aee97f8f-c3d8-4e97-877b-eda39b2798e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import*\n",
    "from pyspark.sql.types import*\n",
    "from pyspark.sql.window import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44df9ea1-4205-442f-b220-de00a4fba250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog claims_leakage;\n",
    "use schema silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f19519-4f7a-4da6-82b1-95a1cbf31312",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATE_FORMATS = [\n",
    "    \"yyyy-MM-dd\",\n",
    "    \"dd/MM/yy\",\n",
    "    \"MM-dd-yyyy\",\n",
    "    \"MMM dd yyyy\",\n",
    "    \"yyyy/MM/dd\"\n",
    "]\n",
    "\n",
    "def parse_date(col_name):\n",
    "    return coalesce(*[\n",
    "        try_to_timestamp(col(col_name), lit(f))\n",
    "        for f in DATE_FORMATS\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ac2af9-4a5c-4641-b4e7-0a51487d808f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_amount(col_name):\n",
    "    clean=upper(regexp_replace(col(col_name),\",\",\"\"))\n",
    "    base_value=regexp_replace(clean,\"[^0-9,]\",\"\").try_cast(\"double\")\n",
    "\n",
    "    return(\n",
    "        when(clean.endswith(\"L\"),base_value*100000)\n",
    "        .when(clean.endswith(\"K\"),base_value*1000)\n",
    "        .otherwise(base_value)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da8c49fa-828f-4f55-8c68-133451f25d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def normalize(col_name):\n",
    "    return upper(trim(col(col_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b48497c-52bd-43bb-9d2e-d090a161e85b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import builtins\n",
    "\n",
    "def write_batch(df, table_name, mode=\"overwrite\"):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"[START] Batch write | table={table_name} | mode={mode}\")\n",
    "\n",
    "        (\n",
    "            df.write\n",
    "              .format(\"delta\")\n",
    "              .mode(mode)\n",
    "              .option(\"overwriteSchema\", \"true\")\n",
    "              .saveAsTable(table_name)\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if CONFIG[\"logging\"][\"track_execution_time\"]:\n",
    "            duration = end_time - start_time\n",
    "            logger.info(\n",
    "                f\"[END] Batch write | table={table_name} | duration={duration:.2f} sec\"\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[ERROR] Batch write failed | table={table_name}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8419812342148581,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "utilities",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
